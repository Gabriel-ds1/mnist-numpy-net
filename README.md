# ðŸ§  NumPy Digit & Fashion Classifier

> A neural network framework built **entirely from scratch using NumPy** â€” no deep learning libraries, just math, logic, and code.
> Trains on **MNIST** or **Fashion-MNIST**, supports many optimizers and activations, and includes a GUI to classify real-time drawings.
> It supports training on **MNIST** or **Fashion-MNIST** datasets with a wide variety of custom activation functions, learning rate schedules, and optimizers. It also includes a simple Tkinter GUI where you can draw digits or fashion items and have the model predict your drawing. âœ¨

---

## Latest Updates

- Created full softmax + categorical cross entropy functions with forward and backward passes.
- Added GPU support using CuPy
- Added SGD with momentum and Adagrad to Optimizers.py
- Updated model weights with higher epoch count (now that GPU is supported)

## ðŸš€ Features

- âœ… **Built entirely with NumPy â€“ a true from-scratch deep learning model.**
- âœ… Supports **MNIST** and **Fashion-MNIST** datasets.
- âœ… Training, validation, and test split functionality.
- âœ… Custom neural network engine with:
  - Weight initializations: **He**, **Xavier**
  - Optimizers: **SGD**, **Adam**, **RMSprop**, **Adamax** â€“ all manually implemented.
  - Activation functions: **ReLU**, **GELU**, **Swish** and more.. including brand new **custom** activation functions!
  - LR scheduling: **Step** and **Exponential decay**
  - **Dropout** & **L2 regularization**
- âœ… Training visualizations: loss & accuracy plots, confusion matrix.
- âœ…Custom logging for tracking experiments.
- âœ… Easy CLI with [`tyro`](https://github.com/brentyi/tyro)
- âœ… **Tkinter GUI** for drawing digits/clothing and seeing model predictions
- âœ… Easy model saving/loading for testing or deployment.

---

## ðŸ’¡ Custom Activation Functions

One of the unique aspects of this project is the design and testing of completely new activation functions â€” including experimental ones like:

- `reverse_relu`, `chaotic_relu`, `oscillating_relu`, `sin_exp_decay`
- `gravity`, `gravity_x`, and **`gravity_x_swish`** â€” a novel function that **outperformed ReLU and GELU when paired with Adamax**

> ðŸ’¥ In benchmark testing, `gravity_x` + **Adamax** achieved **the highest test accuracy** outperforming all standard activations.

![Custom Activation Functions by: Gabriel Souza](https://i.imgur.com/SG3X9z4.png)

---

## â­ Architecture Overview

- Feedforward fully-connected neural network
- Manual forward & backward propagation
- Cross-entropy loss with softmax output
- Accurate gradient computations per activation

---

## ðŸ“ Project Structure

```bash
â”œâ”€data/                          # MNIST and/or Fashion MNIST are automatically saved here
â”œâ”€images/                        # Project showcase images
â”œâ”€â”€model/
â”‚   â”œâ”€â”€ neural_net.py            # Neural network implementation
â”‚   â”œâ”€â”€ optimizers.py            # Manual optimizers (Adam, SGD, etc.)
â”‚   â”œâ”€â”€ activation_functions.py  # Activation functions & derivatives
â”œâ”€runs/                          # Experiment results will output here by default
â”œâ”€â”€utils/
â”‚   â”œâ”€â”€ data_loader.py           # MNIST & Fashion-MNIST loaders
â”‚   â”œâ”€â”€ helpers.py               # Logging, plotting, saving utils
â”‚   â”œâ”€â”€ logger.py                # Logging, plotting, saving utils
â”‚   â”œâ”€â”€ schedules.py             # Learning rate schedules
â”œâ”€â”€gui.py                        # Interactive drawing classification tool
â”œâ”€â”€train.py                      # Training entry point
â”œâ”€â”€test.py                       # Evaluation-only entry point
```

---

## ðŸ“¦ Setup

```bash
pip install -r requirements.txt
```

Requires only:

- numpy
- matplotlib
- scikit-learn
- pillow
- tyro
- tkinter (standard with Python on most systems)

---

## ðŸ–¥ï¸ GUI Demo (Tkinter)

![GUI Classification Example](https://i.imgur.com/fqWbzYo.gif)

Using the included `gui.py`, you can load any trained model and draw directly in a canvas interface:

```bash
python gui.py --weights runs/checkpoint_20250414-130219/model_weights.npz --dataset mnist
```

-Draw any digit (0â€“9) or fashion item (if using Fashion-MNIST).

-See the predicted class and probability bar chart.

-Swap models or datasets with ease.

---

## ðŸ§ª Training

```bash
python train.py --activation relu --optimizer adam --epochs 20 --batch_size 64 --learning_rate 0.01
```

All training configs are available via CLI thanks to tyro. You can view a full list of available args within the train.py file.

---

## ðŸ“Š Testing

You can download the model weights with the best results from here:

- [MNIST checkpoint v0.03] (https://drive.google.com/uc?export=download&id=1RKPwvUnt6csPZSN_yV02OiLAguuOA0kV)
- [Fashion MNIST checkpoint v0.03] (https://drive.google.com/uc?export=download&id=1Mfc6M2Id_8PG3Ik_ApVjlpQov3KvTjfC)

```bash
python test.py --load_path path/to/model_weights.npz --dataset mnist
```

---

## ðŸ“ Sample Accuracy (MNIST, 200 Epochs)

| Activation      | Optimizer | Test Accuracy |
| --------------- | --------- | ------------- |
| ReLU            | Adamax    | 98.33%        |
| Swish           | Adamax    | 98.30%        |
| Sigmoid         | Adamax    | 96.86%        |
| Gravity_x_swish | Adamax    | 99.95%        |

> Full results and visualizations are saved under `/runs/checkpoint_*/`. Further testing is required with Fashion MNIST.

---

## ðŸ§  Author Notes

This project was a deep dive into the core mechanics of neural networks. Everything â€” from weight initialization to backpropagation, gradient descent to activation design â€” was written line-by-line in NumPy.

Itâ€™s meant not only as a showcase of skills but as an educational tool and playground for experimentation.

---

## ðŸ“£ Contact

If you're a recruiter or collaborator interested in AI, deep learning, or research-driven work â€” feel free to connect!

> gabesouza004@gmail.com
